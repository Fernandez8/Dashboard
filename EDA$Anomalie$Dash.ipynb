{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rom sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "\n",
    "\n",
    "####Function and modules for data analysis and model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_regression\n",
    "\n",
    "\n",
    "#####Function and modules for deep learning models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import LSTM\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "###Function and modules for time series models\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "\n",
    "\n",
    "#####Function and modules for data preparation and visualization\n",
    "# pandas, pandas_datareader, numpy and matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Seaborn for easier visualization\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from plotly.subplots import make_subplots\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from plotly import graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "#Display plots in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    ### EDA \n",
    "\n",
    "data_df = [\n",
    "    go.Heatmap(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        z=z_heatmap,\n",
    "        name = 'produziert <-> retourniert',\n",
    "        xaxis = 'x',\n",
    "        yaxis = 'y',\n",
    "        colorscale = 'Portland', \n",
    "        hoverlabel = dict(namelength = 50)\n",
    "    ),\n",
    "    go.Bar(\n",
    "        x = x_returned_Produk,\n",
    "        y = y_returned_Produk,\n",
    "        name = 'retourniert',\n",
    "        orientation = 'h',\n",
    "        xaxis = 'x2',\n",
    "        marker = dict(\n",
    "            color = 'rgba(34,34,34,0.2)'\n",
    "        ),\n",
    "    ),\n",
    "    go.Bar(\n",
    "        x = x_produced_Produkt,\n",
    "        y = y_produced_Produkt,\n",
    "        name = 'produziert',\n",
    "        yaxis = 'y2',\n",
    "        marker = dict(\n",
    "            color = 'rgba(34,34,34,0.2)'\n",
    "        ),\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        x = df1_total_produkt.df_year_produced,\n",
    "        y = df1_total_produkt.df_propofproduction,\n",
    "        yaxis = 'y3',\n",
    "        name = 'Anteil an Monatsproduktion',\n",
    "        hoverlabel = dict(namelength = 40)),\n",
    "    go.Scatter(\n",
    "        x = df_rate_returned.prop_neue_prod,\n",
    "        y = df_rate_returned_neu_totalPro.year,\n",
    "        xaxis = 'x3',\n",
    "        orientation = 'h',\n",
    "        name = 'Retourenanteil zu aktiven Produkten',\n",
    "        hoverlabel = dict(namelength = 50))\n",
    "        ]\n",
    "layout = go.Layout(\n",
    "    autosize = False,\n",
    "    title = 'Beziehung zwischen Produktionsdatum und Retouren von Produkten',\n",
    "    xaxis = dict(\n",
    "        title = 'Produktionsdatum',\n",
    "        zeroline = False,\n",
    "        domain = [0,0.82],\n",
    "        showgrid = False\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Retourendatum',\n",
    "        zeroline = False,\n",
    "        domain = [0,0.75],\n",
    "        showgrid = False\n",
    "    ),\n",
    "    xaxis2 = dict(\n",
    "        zeroline = False,\n",
    "        domain = [0.85,1],\n",
    "        showgrid = False\n",
    "    ),\n",
    "    xaxis3 = dict(\n",
    "        zerolin\n",
    "\n",
    "layout = go.Layout(\n",
    "    autosize = False,\n",
    "    title = 'Beziehung zwischen Produktionsdatum und Retouren ',\n",
    "    xaxis = dict(\n",
    "        title = 'Produktionsdatum',\n",
    "        zeroline = False,\n",
    "        domain = [0,0.82],\n",
    "        showgrid = False\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Retourendatum',\n",
    "        zeroline = False,\n",
    "        domain = [0,0.75],\n",
    "        showgrid = False\n",
    "    ),\n",
    "    xaxis2 = dict(\n",
    "        zeroline = False,\n",
    "        domain = [0.85,1],\n",
    "        showgrid = False\n",
    "    ),\n",
    "    xaxis3 = dict(\n",
    "        zeroline = False,\n",
    "        domain = [0.85,1],\n",
    "        showgrid = False,\n",
    "        overlaying='x2',\n",
    "        side='top',\n",
    "        tickformat = ',.2%'\n",
    "    ),\n",
    "    yaxis2 = dict(\n",
    "        zeroline = False,\n",
    "        domain = [0.74,1],\n",
    "        showgrid = False\n",
    "    ),\n",
    "    yaxis3 = dict(\n",
    "        zeroline = False,\n",
    "        showgrid = False,\n",
    "        domain = [0.75,1],\n",
    "        overlaying='y2',\n",
    "        side='right',\n",
    "        tickformat = ',.1%'\n",
    "        ),\n",
    "    height = 800,\n",
    "    width = 1280,\n",
    "    bargap = 0,\n",
    "    hovermode = 'closest',\n",
    "    showlegend = False\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data_df, layout=layout)\n",
    "        \n",
    "######################################################################################################################\n",
    "\n",
    "#### Aonomalien in Bstellungen basierend auf \"Payment_Method\" erkennen\n",
    "        \n",
    "def AnomalienPlots(df, features):\n",
    "    fig = make_subplots(\n",
    "                    rows=2,\n",
    "                    cols=1,\n",
    "                    row_heights=[0.7, 0.3],\n",
    "                    print_grid=False,\n",
    "                    vertical_spacing=0.02\n",
    "                    )\n",
    "    \n",
    "    colors=['rgb(178,236,93)','rgb(169,237,109)']\n",
    "    form=[None, 'dot', None, 'dot', None, 'dot', None, 'dot']\n",
    "    widths=[3,4,3,4,3,4]\n",
    "    \n",
    "        \n",
    "    df_line = df['avg_'+feature]\n",
    "    df_UpBound = df['avg_'+features]+df['se_'+features]\n",
    "    df_LowBound = df['avg_'+features]-df['se_'+features]\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "                        x=df['Date'], y=df_line, fill=None, opacity=0.3,\n",
    "                        mode='lines+markers', name=tb_label, line=dict(color='rgb(178,236,93)', width=4, dash=None),\n",
    "                        line_shape='spline'\n",
    "                        ),\n",
    "                        row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(\n",
    "                        x=df['Date'], y=df_UpBound, fill='tonexty', showlegend=False,\n",
    "                        mode='lines', name=tb_label, line=dict(color='rgb(179,109,237)', width=1, dash=None)), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(\n",
    "                        x=df['Date'], y=df_LowBound, fill='tonexty', showlegend=False,\n",
    "                        mode='lines', line=dict(color='rgb(178,236,93)', width=1, dash=None)), row=1, col=1)\n",
    "    fig.update_layout(title={'text':'<b>Zeitverlauf von '+feature+ '</b>', 'x':0.40, 'y':0.95, 'font':{'size':27}},\n",
    "                              xaxis_title='Date',yaxis_title=feature, height=710, legend={'orientation':'h', 'y':1.071, 'x':0, 'font':{'size':15}})\n",
    "    fig = fig.to_html(include_plotlyjs=False,\n",
    "                                full_html=False,\n",
    "                                config={'displayModeBar': False,'editable': False},\n",
    "                                default_width='99%')\n",
    "\n",
    "    print('%html {0}'.format(fig))\n",
    "        \n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Classification\n",
    "\n",
    "#Splitting the variables into predictor and target variables. We need to drop \"Payment_Method\" variables, \n",
    "\n",
    "X = df.drop(['Payment_Method'], axis=1)\n",
    "y = df[\"Payment_Method\"]\n",
    "\n",
    "#Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest and Gradient Boosting (Anwendung von Pipeleine)\n",
    "\n",
    "\n",
    "# Einrichten von Pipelines mit einer StandardScaler-Funktion zum Normalisieren der Variablen\n",
    "pipelines = {\n",
    "    'rf' : make_pipeline(StandardScaler(), \n",
    "                         RandomForestClassifier(random_state=42, class_weight='balanced')),\n",
    "    'gb' : make_pipeline(StandardScaler(), \n",
    "                         GradientBoostingClassifier(random_state=42))\n",
    "}\n",
    "\n",
    "# Einrichten der Hyperparameter für den Random Forest\n",
    "rf_hyperparameters = {\n",
    "    'randomforestclassifier__n_estimators': [100, 200],\n",
    "    'randomforestclassifier__max_features': ['auto', 'sqrt', 0.30]\n",
    "}\n",
    "\n",
    "#Setting up the hyperparameters for the Gradient Boost\n",
    "gb_hyperparameters = {\n",
    "    'gradientboostingclassifier__n_estimators': [100, 200],\n",
    "    'gradientboostingclassifier__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'gradientboostingclassifier__max_depth': [1, 3, 5]\n",
    "}\n",
    "\n",
    "#Erstellen von dictionary der Hyperparameter\n",
    "hyperparameters = {\n",
    "    'rf' : rf_hyperparameters,\n",
    "    'gb' : gb_hyperparameters\n",
    "}\n",
    "\n",
    "\n",
    "# Erstellen eines leeren dictionary für angepasste Modelle\n",
    "fitted_alternative_models = {}\n",
    "\n",
    "# Looping through model pipelines, tuning each with GridSearchCV and saving it to fitted_logreg_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    #Creating cross-validation object from pipeline and hyperparameters\n",
    "    alt_model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    #Fitting the model on X_train, y_train\n",
    "    alt_model.fit(X_train, y_train)\n",
    "    \n",
    "    #Storing the model in fitted_logreg_models[name] \n",
    "    fitted_alternative_models[name] = alt_model\n",
    "    \n",
    "    #Printing the status of the fitting\n",
    "    print(name, 'has been fitted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an empty dictionary for predicted models\n",
    "predicted_alternative_models = {}\n",
    "\n",
    "#Predicting the response variables and displaying the prediction score\n",
    "for name, model in fitted_alternative_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    predicted_alternative_models[name] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "predicted_alternative_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "pd.crosstab(y_test, fitted_alternative_models['rf'].predict(X_test), rownames=['True'], colnames=['Predicted'], margins=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erstellen des Klassifizierungsberichts\n",
    "print(classification_report(y_test, fitted_alternative_models['rf'].predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prognose von Bestellungen\n",
    "#Splitting the variables into predictor and target variables. We need to drop \"Payment_Method\" variables, \n",
    "\n",
    "X = df.drop(['numberOfOrders'], axis=1)\n",
    "y = df[\"numberOfOrders\"]\n",
    "\n",
    "### Wir verwenden 80% des Datensatzes für die Modellierung und 20% für Tests\n",
    "\n",
    "validation_size = 0.2\n",
    "train_size = int(len(X) * (1-validation_size))\n",
    "X_train, X_test = X[0:train_size], X[train_size:len(X)]\n",
    "Y_train, Y_test = Y[0:train_size], Y[train_size:len(X)]\n",
    "\n",
    "####   Regression and tree regression algorithms\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('CART', DecisionTreeRegressor()))\n",
    "models.append(('SVR', SVR()))\n",
    "\n",
    "\n",
    "##Neural network algorithms\n",
    "models.append(('MLP', MLPRegressor()))\n",
    "\n",
    "\n",
    "###Ensemble models\n",
    "\n",
    "# Boosting methods\n",
    "models.append(('ABR', AdaBoostRegressor()))\n",
    "models.append(('GBR', GradientBoostingRegressor()))\n",
    "\n",
    "# Bagging methods\n",
    "models.append(('RFR', RandomForestRegressor()))\n",
    "models.append(('ETR', ExtraTreesRegressor()))\n",
    "\n",
    "num_folds = 10\n",
    "scoring = 'mean_squared_error'\n",
    "\n",
    "names = []\n",
    "kfold_results = []\n",
    "test_results = []\n",
    "train_results = []\n",
    "for name, model in models:\n",
    " names.append(name)\n",
    "\n",
    " ## k-fold analysis:\n",
    " kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    " cv_results = cross_val_score(model, X_train, Y_train, cv=kfold,scoring=scoring)\n",
    " kfold_results.append(cv_results)\n",
    "    \n",
    " # Full Training period\n",
    " res = model.fit(X_train, Y_train)\n",
    " train_result = mean_squared_error(res.predict(X_train), Y_train)\n",
    " train_results.append(train_result)\n",
    " # Test results\n",
    " test_result = mean_squared_error(res.predict(X_test), Y_test)\n",
    " test_results.append(test_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let’s compare the algorithms by looking at the cross validation results\n",
    "\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison: Kfold results')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(kfold_results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(15,8)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training und  test Error\n",
    "# Vergelich algorithms\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ind = np.arange(len(names)) # the x locations for the groups\n",
    "\n",
    "width = 0.35 # the width of the bars\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.bar(ind - width/2, train_results, width=width, label='Train Error')\n",
    "pyplot.bar(ind + width/2, test_results, width=width, label='Test Error')\n",
    "fig.set_size_inches(15,8)\n",
    "pyplot.legend()\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zeitreihenanalyse basierend auf modelle: ARIMA and LSTM\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_Arima_model(arima_order):\n",
    " #predicted = list()\n",
    " modelARIMA=ARIMA(endog=Y_train,exog=X_train_ARIMA,order=arima_order)\n",
    " model_fit = modelARIMA.fit()\n",
    " error = mean_squared_error(Y_train, model_fit.fittedvalues)\n",
    " return error\n",
    "\n",
    "\n",
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(p_values, d_values, q_values):\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for p in p_values:\n",
    "           for d in d_values:\n",
    "                for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                try:\n",
    "                    mse = evaluate_arima_model(order)\n",
    "                    if mse < best_score:\n",
    "                        best_score, best_cfg = mse, order\n",
    " print('ARIMA%s MSE=%.6f' % (order,mse))\n",
    "                except:\n",
    "                    continue\n",
    " print('Best ARIMA%s MSE=%.7f' % (best_cfg, best_score))\n",
    "\n",
    "\n",
    "# Berechnung der  parameter\n",
    "p_values = [0, 1, 2]\n",
    "d_values = range(0, 2)\n",
    "q_values = range(0, 2)\n",
    "evaluate_models(p_values, d_values, q_values)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
